{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('tf': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1b4bd66619e1f63a2810c0f91c748d47860e139f5a175a9a480ebd9d4456bd5e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sklearn\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import *\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_df=[]\n",
    "years_list = [19,18,17,16,15,14,13,12,11,10,'09','08','07','06','05','04','03']\n",
    "year_int = 2020\n",
    "for year in years_list:\n",
    "    #Note: 18 refers to 2019 and so on\n",
    "    temp_spread_df = pd.read_csv(\"C:/Users/FLUXNATURE/Desktop/New Kaggle world/Point Spread/ncaabb\" + str(year) + \".csv\")\n",
    "    temp_spread_df['Season'] = year_int\n",
    "    year_last = year\n",
    "    year_int = year_int-1    \n",
    "    if year==19:\n",
    "        spread_df = temp_spread_df\n",
    "    else:\n",
    "        spread_df = spread_df.append(temp_spread_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_df['home'] = spread_df['home'].str.lower()\n",
    "spread_df['road'] = spread_df['road'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         date      home hscore              road rscore line  lineavg  \\\n",
       "0  11/05/2019   alabama    NaN      pennsylvania    7.5  7.5    10.56   \n",
       "1  11/05/2019  arkansas    NaN              rice     18   18    19.23   \n",
       "2  11/05/2019    auburn    NaN  georgia southern     14   14    15.42   \n",
       "\n",
       "   linesag  linesage  linesagp  linesaggm linemoore lineopen  linedok  \\\n",
       "0    12.40     12.40     12.40      12.40      6.72      7.5     9.74   \n",
       "1    18.58     18.58     18.58      18.58     16.98       18    19.80   \n",
       "2    15.72     15.72     15.72      15.72      5.97     14.5    15.67   \n",
       "\n",
       "   linefox   std  linepugh  linedonc  neutral  linetalis  lineespn  linepir  \\\n",
       "0      9.0  1.92      9.60      10.8      0.0        8.2       NaN      NaN   \n",
       "1     23.0  1.65     20.25      18.5      0.0       21.3       NaN      NaN   \n",
       "2     20.0  3.57     17.79      15.4      0.0       16.4       NaN      NaN   \n",
       "\n",
       "   linepiw  linepib  line7ot  lineer  linedd  linemassey linedunk  lineround  \\\n",
       "0      NaN      NaN      2.0     NaN     NaN        9.62    11.36        NaN   \n",
       "1      NaN      NaN      2.0     NaN     NaN       18.76    20.03        NaN   \n",
       "2      NaN      NaN      2.0     NaN     NaN       18.83      NaN        NaN   \n",
       "\n",
       "   lineteamrnks  Season  lineashby  lineprophet  lineseven  linepig linepom  \\\n",
       "0          12.7    2020        NaN          NaN        NaN      NaN     NaN   \n",
       "1          17.1    2020        NaN          NaN        NaN      NaN     NaN   \n",
       "2          12.1    2020        NaN          NaN        NaN      NaN     NaN   \n",
       "\n",
       "  linemass linerpi linegreen lineash lineargh linemarkov linesauce  \n",
       "0      NaN     NaN       NaN     NaN      NaN        NaN       NaN  \n",
       "1      NaN     NaN       NaN     NaN      NaN        NaN       NaN  \n",
       "2      NaN     NaN       NaN     NaN      NaN        NaN       NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>home</th>\n      <th>hscore</th>\n      <th>road</th>\n      <th>rscore</th>\n      <th>line</th>\n      <th>lineavg</th>\n      <th>linesag</th>\n      <th>linesage</th>\n      <th>linesagp</th>\n      <th>linesaggm</th>\n      <th>linemoore</th>\n      <th>lineopen</th>\n      <th>linedok</th>\n      <th>linefox</th>\n      <th>std</th>\n      <th>linepugh</th>\n      <th>linedonc</th>\n      <th>neutral</th>\n      <th>linetalis</th>\n      <th>lineespn</th>\n      <th>linepir</th>\n      <th>linepiw</th>\n      <th>linepib</th>\n      <th>line7ot</th>\n      <th>lineer</th>\n      <th>linedd</th>\n      <th>linemassey</th>\n      <th>linedunk</th>\n      <th>lineround</th>\n      <th>lineteamrnks</th>\n      <th>Season</th>\n      <th>lineashby</th>\n      <th>lineprophet</th>\n      <th>lineseven</th>\n      <th>linepig</th>\n      <th>linepom</th>\n      <th>linemass</th>\n      <th>linerpi</th>\n      <th>linegreen</th>\n      <th>lineash</th>\n      <th>lineargh</th>\n      <th>linemarkov</th>\n      <th>linesauce</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11/05/2019</td>\n      <td>alabama</td>\n      <td>NaN</td>\n      <td>pennsylvania</td>\n      <td>7.5</td>\n      <td>7.5</td>\n      <td>10.56</td>\n      <td>12.40</td>\n      <td>12.40</td>\n      <td>12.40</td>\n      <td>12.40</td>\n      <td>6.72</td>\n      <td>7.5</td>\n      <td>9.74</td>\n      <td>9.0</td>\n      <td>1.92</td>\n      <td>9.60</td>\n      <td>10.8</td>\n      <td>0.0</td>\n      <td>8.2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.62</td>\n      <td>11.36</td>\n      <td>NaN</td>\n      <td>12.7</td>\n      <td>2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11/05/2019</td>\n      <td>arkansas</td>\n      <td>NaN</td>\n      <td>rice</td>\n      <td>18</td>\n      <td>18</td>\n      <td>19.23</td>\n      <td>18.58</td>\n      <td>18.58</td>\n      <td>18.58</td>\n      <td>18.58</td>\n      <td>16.98</td>\n      <td>18</td>\n      <td>19.80</td>\n      <td>23.0</td>\n      <td>1.65</td>\n      <td>20.25</td>\n      <td>18.5</td>\n      <td>0.0</td>\n      <td>21.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>18.76</td>\n      <td>20.03</td>\n      <td>NaN</td>\n      <td>17.1</td>\n      <td>2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11/05/2019</td>\n      <td>auburn</td>\n      <td>NaN</td>\n      <td>georgia southern</td>\n      <td>14</td>\n      <td>14</td>\n      <td>15.42</td>\n      <td>15.72</td>\n      <td>15.72</td>\n      <td>15.72</td>\n      <td>15.72</td>\n      <td>5.97</td>\n      <td>14.5</td>\n      <td>15.67</td>\n      <td>20.0</td>\n      <td>3.57</td>\n      <td>17.79</td>\n      <td>15.4</td>\n      <td>0.0</td>\n      <td>16.4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>18.83</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12.1</td>\n      <td>2020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "spread_df.head(3)"
   ]
  },
  {
   "source": [
    "Match Team IDs to data from NCAAM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df = pd.read_csv('C:/Users/FLUXNATURE/Desktop/New Kaggle world/NCAAM/MTeamSpellings.csv', sep='\\,', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     TeamNameSpelling  TeamID\n",
       "0    a&m-corpus chris    1394\n",
       "1  a&m-corpus christi    1394\n",
       "2         abilene chr    1101"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TeamNameSpelling</th>\n      <th>TeamID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a&amp;m-corpus chris</td>\n      <td>1394</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a&amp;m-corpus christi</td>\n      <td>1394</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>abilene chr</td>\n      <td>1101</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "teams_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_list = ['home','road']\n",
    "for team in team_list:\n",
    "    spread_df = pd.merge(spread_df, teams_df, left_on=[team], right_on = ['TeamNameSpelling'], how='left')\n",
    "    if team=='home':\n",
    "        spread_df.rename(columns={'TeamID': 'HTeamID'}, inplace=True)\n",
    "    if team=='road':\n",
    "        spread_df.rename(columns={'TeamID': 'RTeamID'}, inplace=True)\n",
    "    spread_df = spread_df.drop(['TeamNameSpelling'], axis=1)"
   ]
  },
  {
   "source": [
    "muldifying home and road to team and score\n",
    "\n",
    "see implemetation below "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_df.loc[spread_df['hscore']>spread_df['rscore'], 'WTeamID'] = spread_df['HTeamID']\n",
    "spread_df.loc[spread_df['hscore']<spread_df['rscore'], 'LTeamID'] = spread_df['HTeamID']\n",
    "\n",
    "spread_df.loc[spread_df['hscore']>spread_df['rscore'], 'WScore'] = spread_df['hscore']\n",
    "spread_df.loc[spread_df['hscore']<spread_df['rscore'], 'LScore'] = spread_df['hscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_df.loc[spread_df['rscore']>spread_df['hscore'], 'WTeamID'] = spread_df['RTeamID']\n",
    "spread_df.loc[spread_df['rscore']<spread_df['hscore'], 'LTeamID'] = spread_df['RTeamID']\n",
    "\n",
    "spread_df.loc[spread_df['rscore']>spread_df['hscore'], 'WScore'] = spread_df['rscore']\n",
    "spread_df.loc[spread_df['rscore']<spread_df['hscore'], 'LScore'] = spread_df['rscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_df.replace([np.inf, -np.inf], np.nan).dropna(subset=['WTeamID','LTeamID','WScore','LScore','line'])\n",
    "spread_df = spread_df[spread_df['WScore'] != \".\"]\n",
    "spread_df = spread_df[spread_df['LScore'] != \".\"]\n",
    "spread_df = spread_df[spread_df['line'] != \".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3.0      1730\n",
       "3.5      1720\n",
       "2.5      1705\n",
       "5.5      1699\n",
       "5.0      1697\n",
       "         ... \n",
       "-79.5       1\n",
       "-20.5       1\n",
       "-60.0       1\n",
       "-77.0       1\n",
       "29.5        1\n",
       "Name: line, Length: 271, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "spread_df['line'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop spreads with bad coverage\n",
    "spread_df = spread_df.drop(['line7ot','lineargh','lineash','lineashby','linedd','linedunk','lineer','linegreen','linemarkov','linemass','linepib','linepig','linepir','linepiw','linepom','lineprophet','linerpi','lineround','linesauce','lineseven','neutral','lineteamrnks','linetalis','lineespn','linemassey','linedonc','linesaggm','std','linepugh','linefox','linedok','lineopen'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             date          home hscore          road rscore  line  lineavg  \\\n",
       "64236  03/30/2004      iowa st.     81       rutgers     84   2.0     1.22   \n",
       "64237  04/01/2004      michigan     62       rutgers     55   5.5     2.06   \n",
       "64238  04/03/2004          duke     78   connecticut     79  -2.0     2.85   \n",
       "64239  04/03/2004  oklahoma st.     67  georgia tech     67   4.5     2.05   \n",
       "64240  04/05/2004   connecticut     82  georgia tech     73   5.0     1.65   \n",
       "\n",
       "       linesag  linesage  linesagp linemoore  Season  HTeamID  RTeamID  \\\n",
       "64236     1.50      1.25      1.74      1.61    2004   1235.0   1353.0   \n",
       "64237     1.51      0.46      2.44      4.47    2004   1276.0   1353.0   \n",
       "64238     2.85      2.24      3.94      1.43    2004   1181.0   1163.0   \n",
       "64239     1.99      3.58      0.52      3.08    2004   1329.0   1210.0   \n",
       "64240     1.12      1.31      0.91      4.57    2004   1163.0   1210.0   \n",
       "\n",
       "       WTeamID  LTeamID WScore LScore  \n",
       "64236   1353.0   1235.0     84     81  \n",
       "64237   1276.0   1353.0     62     55  \n",
       "64238   1163.0   1181.0     79     78  \n",
       "64239      NaN      NaN    NaN    NaN  \n",
       "64240   1163.0   1210.0     82     73  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>home</th>\n      <th>hscore</th>\n      <th>road</th>\n      <th>rscore</th>\n      <th>line</th>\n      <th>lineavg</th>\n      <th>linesag</th>\n      <th>linesage</th>\n      <th>linesagp</th>\n      <th>linemoore</th>\n      <th>Season</th>\n      <th>HTeamID</th>\n      <th>RTeamID</th>\n      <th>WTeamID</th>\n      <th>LTeamID</th>\n      <th>WScore</th>\n      <th>LScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>64236</th>\n      <td>03/30/2004</td>\n      <td>iowa st.</td>\n      <td>81</td>\n      <td>rutgers</td>\n      <td>84</td>\n      <td>2.0</td>\n      <td>1.22</td>\n      <td>1.50</td>\n      <td>1.25</td>\n      <td>1.74</td>\n      <td>1.61</td>\n      <td>2004</td>\n      <td>1235.0</td>\n      <td>1353.0</td>\n      <td>1353.0</td>\n      <td>1235.0</td>\n      <td>84</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>64237</th>\n      <td>04/01/2004</td>\n      <td>michigan</td>\n      <td>62</td>\n      <td>rutgers</td>\n      <td>55</td>\n      <td>5.5</td>\n      <td>2.06</td>\n      <td>1.51</td>\n      <td>0.46</td>\n      <td>2.44</td>\n      <td>4.47</td>\n      <td>2004</td>\n      <td>1276.0</td>\n      <td>1353.0</td>\n      <td>1276.0</td>\n      <td>1353.0</td>\n      <td>62</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>64238</th>\n      <td>04/03/2004</td>\n      <td>duke</td>\n      <td>78</td>\n      <td>connecticut</td>\n      <td>79</td>\n      <td>-2.0</td>\n      <td>2.85</td>\n      <td>2.85</td>\n      <td>2.24</td>\n      <td>3.94</td>\n      <td>1.43</td>\n      <td>2004</td>\n      <td>1181.0</td>\n      <td>1163.0</td>\n      <td>1163.0</td>\n      <td>1181.0</td>\n      <td>79</td>\n      <td>78</td>\n    </tr>\n    <tr>\n      <th>64239</th>\n      <td>04/03/2004</td>\n      <td>oklahoma st.</td>\n      <td>67</td>\n      <td>georgia tech</td>\n      <td>67</td>\n      <td>4.5</td>\n      <td>2.05</td>\n      <td>1.99</td>\n      <td>3.58</td>\n      <td>0.52</td>\n      <td>3.08</td>\n      <td>2004</td>\n      <td>1329.0</td>\n      <td>1210.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>64240</th>\n      <td>04/05/2004</td>\n      <td>connecticut</td>\n      <td>82</td>\n      <td>georgia tech</td>\n      <td>73</td>\n      <td>5.0</td>\n      <td>1.65</td>\n      <td>1.12</td>\n      <td>1.31</td>\n      <td>0.91</td>\n      <td>4.57</td>\n      <td>2004</td>\n      <td>1163.0</td>\n      <td>1210.0</td>\n      <td>1163.0</td>\n      <td>1210.0</td>\n      <td>82</td>\n      <td>73</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "spread_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             date          home hscore               road rscore  line  \\\n",
       "0      11/05/2019       alabama    NaN       pennsylvania    7.5   7.5   \n",
       "1      11/05/2019      arkansas    NaN               rice     18    18   \n",
       "2      11/05/2019        auburn    NaN   georgia southern     14    14   \n",
       "3      11/05/2019           byu    NaN  cal st. fullerton   15.5  15.5   \n",
       "4      11/05/2019        baylor    NaN   central arkansas   26.5  26.5   \n",
       "...           ...           ...    ...                ...    ...   ...   \n",
       "64236  03/30/2004      iowa st.     81            rutgers     84   2.0   \n",
       "64237  04/01/2004      michigan     62            rutgers     55   5.5   \n",
       "64238  04/03/2004          duke     78        connecticut     79  -2.0   \n",
       "64239  04/03/2004  oklahoma st.     67       georgia tech     67   4.5   \n",
       "64240  04/05/2004   connecticut     82       georgia tech     73   5.0   \n",
       "\n",
       "       lineavg  linesag  linesage  linesagp linemoore  Season  HTeamID  \\\n",
       "0        10.56    12.40     12.40     12.40      6.72    2020   1104.0   \n",
       "1        19.23    18.58     18.58     18.58     16.98    2020   1116.0   \n",
       "2        15.42    15.72     15.72     15.72      5.97    2020   1120.0   \n",
       "3        13.72    15.69     15.69     15.69      8.86    2020   1140.0   \n",
       "4        24.66    25.88     25.88     25.88     16.69    2020   1124.0   \n",
       "...        ...      ...       ...       ...       ...     ...      ...   \n",
       "64236     1.22     1.50      1.25      1.74      1.61    2004   1235.0   \n",
       "64237     2.06     1.51      0.46      2.44      4.47    2004   1276.0   \n",
       "64238     2.85     2.85      2.24      3.94      1.43    2004   1181.0   \n",
       "64239     2.05     1.99      3.58      0.52      3.08    2004   1329.0   \n",
       "64240     1.65     1.12      1.31      0.91      4.57    2004   1163.0   \n",
       "\n",
       "       RTeamID  WTeamID  LTeamID WScore LScore  \n",
       "0       1335.0      NaN      NaN    NaN    NaN  \n",
       "1       1349.0      NaN      NaN    NaN    NaN  \n",
       "2       1204.0      NaN      NaN    NaN    NaN  \n",
       "3       1168.0      NaN      NaN    NaN    NaN  \n",
       "4       1146.0      NaN      NaN    NaN    NaN  \n",
       "...        ...      ...      ...    ...    ...  \n",
       "64236   1353.0   1353.0   1235.0     84     81  \n",
       "64237   1353.0   1276.0   1353.0     62     55  \n",
       "64238   1163.0   1163.0   1181.0     79     78  \n",
       "64239   1210.0      NaN      NaN    NaN    NaN  \n",
       "64240   1210.0   1163.0   1210.0     82     73  \n",
       "\n",
       "[63657 rows x 18 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>home</th>\n      <th>hscore</th>\n      <th>road</th>\n      <th>rscore</th>\n      <th>line</th>\n      <th>lineavg</th>\n      <th>linesag</th>\n      <th>linesage</th>\n      <th>linesagp</th>\n      <th>linemoore</th>\n      <th>Season</th>\n      <th>HTeamID</th>\n      <th>RTeamID</th>\n      <th>WTeamID</th>\n      <th>LTeamID</th>\n      <th>WScore</th>\n      <th>LScore</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11/05/2019</td>\n      <td>alabama</td>\n      <td>NaN</td>\n      <td>pennsylvania</td>\n      <td>7.5</td>\n      <td>7.5</td>\n      <td>10.56</td>\n      <td>12.40</td>\n      <td>12.40</td>\n      <td>12.40</td>\n      <td>6.72</td>\n      <td>2020</td>\n      <td>1104.0</td>\n      <td>1335.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11/05/2019</td>\n      <td>arkansas</td>\n      <td>NaN</td>\n      <td>rice</td>\n      <td>18</td>\n      <td>18</td>\n      <td>19.23</td>\n      <td>18.58</td>\n      <td>18.58</td>\n      <td>18.58</td>\n      <td>16.98</td>\n      <td>2020</td>\n      <td>1116.0</td>\n      <td>1349.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11/05/2019</td>\n      <td>auburn</td>\n      <td>NaN</td>\n      <td>georgia southern</td>\n      <td>14</td>\n      <td>14</td>\n      <td>15.42</td>\n      <td>15.72</td>\n      <td>15.72</td>\n      <td>15.72</td>\n      <td>5.97</td>\n      <td>2020</td>\n      <td>1120.0</td>\n      <td>1204.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11/05/2019</td>\n      <td>byu</td>\n      <td>NaN</td>\n      <td>cal st. fullerton</td>\n      <td>15.5</td>\n      <td>15.5</td>\n      <td>13.72</td>\n      <td>15.69</td>\n      <td>15.69</td>\n      <td>15.69</td>\n      <td>8.86</td>\n      <td>2020</td>\n      <td>1140.0</td>\n      <td>1168.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11/05/2019</td>\n      <td>baylor</td>\n      <td>NaN</td>\n      <td>central arkansas</td>\n      <td>26.5</td>\n      <td>26.5</td>\n      <td>24.66</td>\n      <td>25.88</td>\n      <td>25.88</td>\n      <td>25.88</td>\n      <td>16.69</td>\n      <td>2020</td>\n      <td>1124.0</td>\n      <td>1146.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>64236</th>\n      <td>03/30/2004</td>\n      <td>iowa st.</td>\n      <td>81</td>\n      <td>rutgers</td>\n      <td>84</td>\n      <td>2.0</td>\n      <td>1.22</td>\n      <td>1.50</td>\n      <td>1.25</td>\n      <td>1.74</td>\n      <td>1.61</td>\n      <td>2004</td>\n      <td>1235.0</td>\n      <td>1353.0</td>\n      <td>1353.0</td>\n      <td>1235.0</td>\n      <td>84</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>64237</th>\n      <td>04/01/2004</td>\n      <td>michigan</td>\n      <td>62</td>\n      <td>rutgers</td>\n      <td>55</td>\n      <td>5.5</td>\n      <td>2.06</td>\n      <td>1.51</td>\n      <td>0.46</td>\n      <td>2.44</td>\n      <td>4.47</td>\n      <td>2004</td>\n      <td>1276.0</td>\n      <td>1353.0</td>\n      <td>1276.0</td>\n      <td>1353.0</td>\n      <td>62</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>64238</th>\n      <td>04/03/2004</td>\n      <td>duke</td>\n      <td>78</td>\n      <td>connecticut</td>\n      <td>79</td>\n      <td>-2.0</td>\n      <td>2.85</td>\n      <td>2.85</td>\n      <td>2.24</td>\n      <td>3.94</td>\n      <td>1.43</td>\n      <td>2004</td>\n      <td>1181.0</td>\n      <td>1163.0</td>\n      <td>1163.0</td>\n      <td>1181.0</td>\n      <td>79</td>\n      <td>78</td>\n    </tr>\n    <tr>\n      <th>64239</th>\n      <td>04/03/2004</td>\n      <td>oklahoma st.</td>\n      <td>67</td>\n      <td>georgia tech</td>\n      <td>67</td>\n      <td>4.5</td>\n      <td>2.05</td>\n      <td>1.99</td>\n      <td>3.58</td>\n      <td>0.52</td>\n      <td>3.08</td>\n      <td>2004</td>\n      <td>1329.0</td>\n      <td>1210.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>64240</th>\n      <td>04/05/2004</td>\n      <td>connecticut</td>\n      <td>82</td>\n      <td>georgia tech</td>\n      <td>73</td>\n      <td>5.0</td>\n      <td>1.65</td>\n      <td>1.12</td>\n      <td>1.31</td>\n      <td>0.91</td>\n      <td>4.57</td>\n      <td>2004</td>\n      <td>1163.0</td>\n      <td>1210.0</td>\n      <td>1163.0</td>\n      <td>1210.0</td>\n      <td>82</td>\n      <td>73</td>\n    </tr>\n  </tbody>\n</table>\n<p>63657 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "spread_df.dropna(subset=['line'])"
   ]
  },
  {
   "source": [
    "Write the data to a csv"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_df.to_csv('spreads_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}